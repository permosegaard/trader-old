#!/usr/bin/env python3

### START NOTES
#
# cat /tmp/trader.log | egrep -v -e '^[A-Z]{3,8}: 2015-.*$' -e "^$" -e "received tick|INSERT|Recieved partial|parsed data|uuid|Next wakeup|Removed job|yielding with|returning '|passing arguments|processing line|in data|received value|checking market|archived|updated|executed successfully|Starting new|using schedule|Added job|Looking for|entry with symbol|received data|GET|POST|Running job|not enough samples|stale symbol|SELECT|following history|socket|stream from|already following|returning with|incorrect data|is open|added|outside time|received response|extracted data|pruned|request sent|\(Timestamp\('"
#
### END NOTES

# project level TODOs
# TODO: swap assertions for typing support, requires 3.5 and a distro that provides it
# TODO: explore "https://www.quandl.com/" for more data sources - try for a realtime streaming source
# TODO: look into betting markets and time delays/indicators/etc.
# TODO: look at currency for indicators/patterns/etc.
# TODO: commodities? gold, etc.
# TODO: find good twitter data sources and watch them for tips/etc.
# TODO: bitcoin?? :|
# TODO: optimisation
# TODO: +   > better to ask for forgiveness, specifically related to try-except over conditionals
# TODO: +   > run through profiler in pycharm
# TODO: swap to decimal where there's floats as it's less prone to rounding errors, also fraction type!
# TODO: GIL fixers are horrible, move some stuff to a web fetching process - makes it easier to move/proxy??
# TODO: +   > need to consider memory footprint of doing this... ?
# TODO: +   > libcurl could be a viable alternative as it releases the GIL and would hard timeout...?
# TODO: currency conversation on buying and selling (with charges)?
# TODO: swap everything over to the retriever class, work out how to add streaming function... ? -- copy socket code over?
# TODO: if money is less than threshold, shutdown the process so it can restart
# TODO: stop currency updates if no markets are open?
# TODO: can you add a shia lebeouf "DO IT" for when there's a buy alert?
# TODO: move to config system that can hide urls in a config. that isn't in github
# TODO: orderbook minimum quantity buy??

# setup logging before anything else tries to use it # TODO: file output if config
import inspect, io, logging, sys, traceback
class LoggerMeta( logging.getLoggerClass() ): # copied from logging source with minor mod
    def findCaller(self, stack_info=False):
        f = inspect.stack()[ 3 ][ 0 ] # this fixes abstracting the logger class
        if f is not None: f = f.f_back
        rv = "(unknown file)", 0, "(unknown function)", None
        while hasattr(f, "f_code"):
            co = f.f_code
            sinfo = None
            if stack_info:
                sio = io.StringIO()
                sio.write('Stack (most recent call last):\n')
                traceback.print_stack(f, file=sio)
                sinfo = sio.getvalue()
                if sinfo[-1] == '\n': sinfo = sinfo[:-1]
                sio.close()
            rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)
            break
        return rv
logging.setLoggerClass( LoggerMeta )

# concise imports here
import base64, datetime, io, json, math, os, random, re, signal, socket, time, threading, uuid # stdlib imports here
import pandas, psycopg2, psycopg2.extras, pycurl # external imports here

# stdlib specific library imports here
from decimal import Decimal
from enum import Enum, unique
from itertools import chain
from logging.handlers import TimedRotatingFileHandler

# external specific import here
from apscheduler.events import EVENT_JOB_EXECUTED, EVENT_JOB_ERROR
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from bs4 import BeautifulSoup
from elasticsearch import Elasticsearch
from money import XMoney, xrates

# config magic here
class ConfigMeta( type ):
    def __iter__( self ):
        for item in self.__dict__: yield item

    def __setattr__( self, name, value ):
        if hasattr( self, name ):
            if type( value ) is type( getattr( self, name ) ):
                super().__setattr__( name, value )
            else: raise TypeError( "expected '{source}' got '{destination}'".format( source=type( value ), destination=type( getattr( self, name ) ) ) )
        else: raise AttributeError( "{name} not found".format( name=name ) )

class Config( metaclass=ConfigMeta ): # TODO: read from file/envs ? # TODO: differentiate between runtime and startup attribs?? # TODO: subscribe to changes??
    """abused enum instance to hold app config"""
    ABBREVIATE_DEBUG_OUTPUT = bool( False )

#    PROXY_HOST = "home.proxies.acionconsultancy.int"
#    PROXY_PORT = 3128

    LOGGING_NAME = "3lkd0ef4oi3ofw0e" # randomly generated by hand mashing
    LOGGING_PATH = "/tmp/trader.log"

    SCHEDULER_MAX_THREADS = int( 200 )

    INTERFACE_PROMPT = str( "> " )
    INTERFACE_SOCKET_PATH = str( "/tmp/trader.sock" )

    #PUBLISHER_DESTINATION = "http://website.dev.host.acionconsultancy.int:8080/"
    PUBLISHER_DESTINATION = "http://169.254.254.5/"

    DATASTORE_POSTGRES_DB = str( "trader" )
    DATASTORE_POSTGRES_HOST = str( "127.0.0.1" )
    DATASTORE_POSTGRES_USER = str( "trader" )
    DATASTORE_POSTGRES_PASS = str( "HCeJAUjeFxvcmzF3T0M0p93hzSJMp" )

    MARKET_WEEKDAY_RANGE = [ 1, 2, 3, 4, 5 ] # range() sucks! # days in 0-6

    MARKET_OPEN_TIME = int( 8 ) # hours in 24
    MARKET_CLOSE_TIME = int( 14 ) # hours in 24

    MARKET_GET_GAINERS_TIMEOUT = int( 10 )
    MARKET_STREAMING_SOCKET_TIMEOUT = int( 60 * 60 ) # seconds: related to SYMBOL_FOLLOWER_MAX_RUNTIME

    MARKET_GAINERS_RATE_THRESHOLD = int( 10 ) # percent

    SYMBOL_FOLLOWER_MAX_RUNTIME = datetime.timedelta( minutes = 60 ) # related to STREAMING_DATA_SOCKET_TIMEOUT
    SYMBOL_FOLLOWER_STALE_THRESHOLD = datetime.timedelta( minutes = 30 )
    SYMBOL_FOLLOWER_CHANGE_THRESHOLD = float( 0.10 ) # percentage without the (* 100)
    SYMBOL_FOLLOWER_BACKOFF_THRESHOLD = datetime.timedelta( hours = 12 )
    SYMBOL_FOLLOWER_HISTORICAL_FROM = datetime.timedelta( days = 4 )
    SYMBOL_FOLLOWER_HISTORICAL_TO = datetime.timedelta( days = 1 )
    SYMBOL_FOLLOWER_VOLUME_THRESHOLD = float( 3 ) # percent without the (* 100)
    SYMBOL_FOLLOWER_VOLUME_LOWER_LIMIT = float( 100 )

    SYMBOL_FOLLOWER_SELL_TIMELIMIT = datetime.timedelta( minutes = 30 )

    TRADE_COST_BUY = XMoney( 10, "USD" )
    TRADE_COST_SELL = XMoney( 10, "USD" )

    ORDERBOOK_SEED_BUDGET = XMoney( 10000, "USD" )
    ORDERBOOK_MAXIMUM_SPEND = float( 0.1 ) # percent without the (* 100)
    ORDERBOOK_MINIMUM_ORDER = int( 5 ) # amount of shares

# enums here
@unique
class MarketsList( Enum ):
    """Enum of possible markets"""
    # TODO: https://ca.help.yahoo.com/kb/finance/exchanges-data-providers-yahoo-finance-sln2310.html?impressions=true for more!
    # TODO: http://www.investing.com/indices/major-indices see indicies codes for more tips
    # TODO: change currencies below to use an ENUM so we don't get string bugs!
    # TODO: offsets and currencies at https://en.wikipedia.org/wiki/List_of_stock_exchanges#Major_stock_exchanges
    # TODO: go through ex's wiki pages and work out actual start times ala. ASX
    TSX = { "symbol": "to", "offset": -5, "currency": "CAD" } # Toronto Stock Exchange
    NYSE = { "symbol": "nq", "offset": -5, "currency": "USD" } # New York Stock Exchange
    NSADAQ = { "symbol": "o", "offset": -5, "currency": "USD" } # US Tech focused
    LSE = { "symbol": "l", "offset": 0, "currency": "GBP" } # London Stock Exchange
    FTSE_AIM = { "symbol": "ftai", "offset": 0, "currency": "GBP" } # Financial Times Stock Index - Alternative Investment Market
    DB1 = { "symbol": "de", "offset": +1, "currency": "EUR" } # Frankfurt Stock Exchange
    NSE = { "symbol": "ns", "offset": +5.5, "currency": "INR" } # India National Stock Exchange
    SSE = { "symbol": "ss", "offset": +8, "currency": "CNY" } # Shanghai Stock Exchange # offset needs checking
    HK = { "symbol": "hk", "offset": +8, "currency": "HKD" } # Hong Kong Stock Exchange
    ASX = { "symbol": "ax", "offset": +11 - 2, "currency": "AUD" } # Australian Stock Exchange

    ##additional markets for future consideration
    ##FTSE_FLEDGLING = { "symbol": "nsx.l", "offset": 0, "currency": "GBP" } # Financial Times Stock Index - Fledgling
    ##FTSE_100 = { "symbol": "ftse", "offset": 0, "currency": "GBP" } # Financial Times Stock Index - Top 100
    ##FTSE_250 = { "symbol": "ftmc", "offset": 0, "currency": "GBP" } # Financial Times Stock Index - Top 250
    ##FTSE_ALL = { "symbol": "ftas", "offset": 0, "currency": "GBP" } # Financial Times Stock Index - All Stocks
    ##FTSE_AIM = { "symbol": "ftai", "offset": 0, "currency": "GBP" } # Financial Times Stock Index - Alternative Investment Market
    ##EUROSTOX_50 = { "symbol": "stoxx50e", "offset": +1, "currency": "EUR" } # Eurozone Stocks Top 50?
    ##BSE = { "symbol": "bo", "offset": +5.5, "currency": "INR" } # Bombay Stock Exchange
    ##SZSE = { "symbol": "sz", "offset": +8, "currency": "CNY" } # Shenzhen Stock Exchange
    ##SGX = { "symbol": "si", "offset": +8, "currency": "SGD" } # Singapore Stock Exchange


@unique
class YFStreamerOptionsList( Enum ):
    """Enum of options for the yahoo streamer api"""
    a00 = "ask price"
    a50 = "ask quantity"
    b00 = "bid price"
    b20 = "b20"
    b30 = "b30"
    b60 = "bid quantity"
    c10 = "percentage change"
    c60 = "c60"
    c63 = "c63"
    c64 = "c64"
    c81 = "c81"
    c82 = "c82"
    c85 = "c85"
    c86 = "c86"
    g00 = "days low"
    h00 = "days high"
    l10 = "last trade price"
    l84 = "l84"
    l86 = "l86"
    l90 = "l90"
    l91 = "l91"
    o40 = "o40"
    o50 = "o50"
    p20 = "price change"
    p40 = "p40"
    p41 = "p41"
    p43 = "p43"
    p44 = "p44"
    t10 = "last trade time (looks like it has 1min accuracy only)"
    t50 = "t50"
    t51 = "t51"
    t53 = "t53"
    t54 = "t54"
    v00 = "cumulative volume"
    z02 = "z02"
    z08 = "z08"
    z09 = "z09"


@unique
class YQLSymbolOptionsList( Enum ):
    AfterHoursChangeRealtime = { "name": "AfterHoursChangeRealtime", "type": None }
    AnnualizedGain = { "name": "AnnualizedGain", "type": str }
    Ask = { "name": "Ask", "type": float }
    AskRealtime = { "name": "AskRealtime", "type": float }
    AverageDailyVolume = { "name": "AverageDailyVolume", "type": int }
    Bid = { "name": "Bid", "type": float }
    BidRealtime = { "name": "BidRealtime", "type": float }
    BookValue = { "name": "BookValue", "type": float }
    Change = { "name": "Change", "type": float }
    ChangeFromFiftydayMovingAverage = { "name": "ChangeFromFiftydayMovingAverage", "type": float }
    ChangeFromTwoHundreddayMovingAverage = { "name": "ChangeFromTwoHundreddayMovingAverage", "type": float }
    ChangeFromYearHigh = { "name": "ChangeFromYearHigh", "type": float }
    ChangeFromYearLow = { "name": "ChangeFromYearLow", "type": float }
    ChangePercentRealtime = { "name": "ChangePercentRealtime", "type": None }
    ChangeRealtime = { "name": "ChangeRealtime", "type": None }
    Change_PercentChange = { "name": "Change_PercentChange", "type": str }
    ChangeinPercent = { "name": "ChangeinPercent", "type": float }
    Commission = { "name": "Commission", "type": None }
    Currency = { "name": "Currency", "type": str }
    DaysHigh = { "name": "DaysHigh", "type": float }
    DaysLow = { "name": "DaysLow", "type": float }
    DaysRange = { "name": "DaysRange", "type": str }
    DaysRangeRealtime = { "name": "DaysRangeRealtime", "type": None }
    DaysValueChange = { "name": "DaysValueChange", "type": None }
    DaysValueChangeRealtime = { "name": "DaysValueChangeRealtime", "type": None }
    DividendPayDate = { "name": "DividendPayDate", "type": str }
    DividendShare = { "name": "DividendShare", "type": float }
    DividendYield = { "name": "DividendYield", "type": float }
    EBITDA = { "name": "EBITDA", "type": str }
    EPSEstimateCurrentYear = { "name": "EPSEstimateCurrentYear", "type": float }
    EPSEstimateNextQuarter = { "name": "EPSEstimateNextQuarter", "type": float }
    EPSEstimateNextYear = { "name": "EPSEstimateNextYear", "type": float }
    EarningsShare = { "name": "EarningsShare", "type": float }
    ErrorIndicationreturnedforsymbolchangedinvalid = { "name": "ErrorIndicationreturnedforsymbolchangedinvalid", "type": None }
    ExDividendDate = { "name": "ExDividendDate", "type": str }
    FiftydayMovingAverage = { "name": "FiftydayMovingAverage", "type": float }
    HighLimit = { "name": "HighLimit", "type": None }
    HoldingsGain = { "name": "HoldingsGain", "type": None }
    HoldingsGainPercent = { "name": "HoldingsGainPercent", "type": None }
    HoldingsGainPercentRealtime = { "name": "HoldingsGainPercentRealtime", "type": None }
    HoldingsGainRealtime = { "name": "HoldingsGainRealtime", "type": None }
    HoldingsValue = { "name": "HoldingsValue", "type": None }
    HoldingsValueRealtime = { "name": "HoldingsValueRealtime", "type": None }
    LastTradeDate = { "name": "LastTradeDate", "type": str }
    LastTradePriceOnly = { "name": "LastTradePriceOnly", "type": float }
    LastTradeRealtimeWithTime = { "name": "LastTradeRealtimeWithTime", "type": None }
    LastTradeTime = { "name": "LastTradeTime", "type": str }
    LastTradeWithTime = { "name": "LastTradeWithTime", "type": str }
    LowLimit = { "name": "LowLimit", "type": None }
    MarketCapRealtime = { "name": "MarketCapRealtime", "type": None }
    MarketCapitalization = { "name": "MarketCapitalization", "type": str }
    MoreInfo = { "name": "MoreInfo", "type": None }
    Name = { "name": "Name", "type": str }
    Notes = { "name": "Notes", "type": None }
    OneyrTargetPrice = { "name": "OneyrTargetPrice", "type": float }
    Open = { "name": "Open", "type": float }
    OrderBookRealtime = { "name": "OrderBookRealtime", "type": None }
    PEGRatio = { "name": "PEGRatio", "type": float }
    PERatio = { "name": "PERatio", "type": float }
    PERatioRealtime = { "name": "PERatioRealtime", "type": None }
    PercebtChangeFromYearHigh = { "name": "PercebtChangeFromYearHigh", "type": float }
    PercentChange = { "name": "PercentChange", "type": float }
    PercentChangeFromFiftydayMovingAverage = { "name": "PercentChangeFromFiftydayMovingAverage", "type": float }
    PercentChangeFromTwoHundreddayMovingAverage = { "name": "PercentChangeFromTwoHundreddayMovingAverage", "type": float }
    PercentChangeFromYearLow = { "name": "PercentChangeFromYearLow", "type": float }
    PreviousClose = { "name": "PreviousClose", "type": float }
    PriceBook = { "name": "PriceBook", "type": float }
    PriceEPSEstimateCurrentYear = { "name": "PriceEPSEstimateCurrentYear", "type": float }
    PriceEPSEstimateNextYear = { "name": "PriceEPSEstimateNextYear", "type": float }
    PricePaid = { "name": "PricePaid", "type": None }
    PriceSales = { "name": "PriceSales", "type": float }
    SharesOwned = { "name": "SharesOwned", "type": None }
    ShortRatio = { "name": "ShortRatio", "type": float }
    StockExchange = { "name": "StockExchange", "type": str }
    Symbol = { "name": "Symbol", "type": str }
    symbol = { "name": "symbol", "type": None } # leave as none for autodeduplication magic
    TickerTrend = { "name": "TickerTrend", "type": None }
    TradeDate = { "name": "TradeDate", "type": None }
    TwoHundreddayMovingAverage = { "name": "TwoHundreddayMovingAverage", "type": float }
    Volume = { "name": "Volume", "type": int }
    YearHigh = { "name": "YearHigh", "type": float }
    YearLow = { "name": "YearLow", "type": float }
    YearRange = { "name": "YearRange", "type": str }


# exceptions here
class MarketRetrieveException( Exception ): pass
class MarketParseException( Exception ): pass
class MarketSortException( Exception ): pass


# classes here
class MarketData():
    """Class for retrieving and manipulating market data from various sources"""

    @staticmethod
    def is_market_open( market ):

        assert isinstance( market, MarketsList )

        Logger.debug( "checking market '{market}' with offset '{offset}'".format( market=market.name, offset=market.value[ "offset" ] ) )

        now = datetime.datetime.utcnow()
        if now.date().isoweekday() not in list( Config.MARKET_WEEKDAY_RANGE ):
            Logger.debug( "market '{market}' is not open as not weekday".format( market=market.name ) )
            return False

        offset = datetime.timedelta( hours = market.value[ "offset" ] )
        if not( Config.MARKET_OPEN_TIME <= ( datetime.datetime.utcnow() + offset ).hour <= Config.MARKET_CLOSE_TIME ):
            Logger.debug( "market '{market}' is not open as outside time range".format( market=market.name ) )
            return False

        Logger.debug( "market '{market}' is open".format( market=market.name ) )
        return True

# yahoo finance market gainer functions here
    @staticmethod
    def list_gainers( market ):
        """
        Fetch list of rising symbols from Yahoo Finance for a given market

        Args:
            market: An element from the MarketsList enum ie. MarketsList.LSE

        Returns:
            A list of elements containing symbol name, company name and change percentage as float ...

             [{'exchange': 'NYSE', 'change': '1.88', 'company': 'ONESAVINGS BK', 'symbol': 'OSB.L'},
             {'exchange': 'NYSE', 'change': '1.76', 'company': 'DS SMITH ', 'symbol': 'SMDS.L'},
             {'exchange': 'NYSE', 'change': '1.68', 'company': 'BIOTECH GRW TRS', 'symbol': 'BIOG.L'}]

             ... or an empty list if no risers found

        Raises:
            MarketRetrieveException: An error curred retrieving the data
            MarketParseException: An error occurred parsing the data
        """

        assert isinstance( market, MarketsList )

        try:
            response = Retriever.blocking_get( "https://uk.finance.yahoo.com/gainers?e={market}".format( market=market.value[ "symbol" ] ), timeout=Config.MARKET_GET_GAINERS_TIMEOUT )
        except Exception as exception: raise MarketRetrieveException( exception )

        Logger.debug( "received response '{response}'".format( response=Logger.abbrev( response, force=True ) ) )

        try:
            soup = BeautifulSoup( response, "html5lib" )
        except Exception as exception: raise MarketParseException( exception )

        return_list = list()

        Logger.debug( "extracted data {soup} from dom".format( soup=Logger.abbrev( str( soup ), force=True ) ) )

        for tr in soup.find( id = "yfitp" ).find( "tbody" ).find_all( "tr" ):
            try:
                symbol = tr.find( "td", attrs={ "class": "first" } ).find( "a" ).text
                company = tr.find( "td", attrs={ "class": "second name" } ).text
                change = tr.findAll( "td" )[ 3 ].text
            except Exception as exception: raise MarketParseException( exception )

            if "N/A" not in change:
                try:
                    change = float( re.match( ".*\((.*)%\).*", change ).group( 1 ) )
                except Exception as exception: raise MarketParseException( exception )

                return_list.append( { "exchange": market, "symbol": symbol, "company": company, "change": change } )

        Logger.debug( "returning with '{returns}' for '{market}'".format( returns=Logger.abbrev( str( return_list ), force=True ), market=market ) )

        return return_list

    @staticmethod
    def __sort_gainers( gainers, ascending=None ):
        """
        ***PRIVATE*** Sort list of gainers by change percentage and direction

        Args:
            gainers: List of gainers as provided by list_gainers

        Returns:
            A list of the same format as the gainers arg sorted by change and direction (ascending arg)

        Raises:
            MarketSortException: An error occurred trying to sort the list
        """

        assert isinstance( gainers, list )
        assert isinstance( ascending, bool )

        gainers_sorted = list()

        try:
            if ascending: gainers_sorted = sorted( gainers, key=lambda gainer: gainer[ "change" ], reverse=False )
            elif not ascending: gainers_sorted = sorted( gainers, key=lambda gainer: gainer[ "change" ], reverse=True )
            else: raise RuntimeError( "'ascending' option is required" )
        except Exception as exception: raise MarketSortException( exception )

        return gainers_sorted

    @staticmethod
    def sort_gainers_ascending( gainers ):
        """
        Sort list of gainers by change percentage

        Args:
            gainers: A list of gainers as provided by list_gainers

        Returns:
            An ascending list of the same format as the gainers arg sorted by change
        """

        assert isinstance( gainers, list )

        return MarketData.__sort_gainers( gainers, ascending=True )

    @staticmethod
    def sort_gainers_descending( gainers ):
        """
        Sort list of gainers by change percentage

        Args:
            gainers: A list of gainers as provided by list_gainers

        Returns:
            A descending list of the same format as the gainers arg sorted by change
        """

        assert isinstance( gainers, list )

        return MarketData.__sort_gainers( gainers, ascending=False )

    @staticmethod
    def remove_gainers_below_value( gainers, minimum ):
        """
        Remove list items below minimum in change key

        Args:
            gainers: A list of gainers as provided by list_gainers
            minimum: Elements with values below this will be removed

        Returns:
            A list of the same format as gainers arg
        """

        assert isinstance( gainers, list )
        assert isinstance( minimum, ( int, float ) )

        results = [ gainer for gainer in gainers if gainer[ "change" ] >= minimum ]

        Logger.debug( "gainers pruned from '{source}' to '{pruned}'".format( source=str( len( gainers ) ), pruned=str( len( results ) ) ) )

        return results

# yahoo finance symbol streaming functions here
    @staticmethod
    def stream_symbol_data( symbols, options ):

        assert isinstance( symbols, ( str, list ) )
        assert isinstance( options, ( YFStreamerOptionsList, list ) )

        if isinstance( symbols, list ): symbols = ",".join( symbols )

        if isinstance( options, str ): options = options.name
        elif isinstance( options, list ): options = ",".join( [ option.name for option in options ] )
        else: raise RuntimeError( "'options' not a str or list" )

        try:
            # format taken from "https://github.com/jd-carroll/yahoo-streamer/blob/master/yahoo.streamer/src/yahoo/streamer/core/YahooConnector.java"
            url = ( "/streamer/1.0?"
                    "s={symbols}&o={symbols}"
                    "&j={options}"
                    "&k={options}"
                    "&callback=parent.yfs_u1f"
                    "&mktmcb=parent.yfs_mktmcb"
                    "&gencallback=parent.yfs_gencb" ).format( symbols=symbols, options=options )

            Logger.debug( "starting to stream from '{url}'".format( url=url ) )

            for line in Retriever.streaming_get_by_line( "streamerapi.finance.yahoo.com", 80, url, http_version="1.0" ):
                Logger.debug( "processing line '{line}'".format( line=line ) )

                for symbol in re.finditer( "yfs_u1f\({\"(?P<symbol>.+?)\":{(?P<data>.+?)}}\)", line ):
                    Logger.debug( "processing entry with symbol '{symbol}' and data '{data}'".format( symbol=symbol.group( "symbol" ), data=symbol.group( "data" ) ) )

                    data_dict = dict()

                    for element in re.finditer( '(?P<key>[a-zA-Z0-9]*):\"(?P<value>[+-a-zA-Z0-9]*)\"[,]?', symbol.group( "data" ) ):
                        Logger.debug( "found '{element}' in data '{data}'".format( element=element, data=symbol.group( "data" ) ) )

                        parsed = MarketData.parse_stream_data( element.group( "value" ) )
                        Logger.debug( "parsed data '{parsed}' from element '{element}'".format( parsed=parsed, element=element ) )

                        data_dict[ element.group( "key" ) ] = parsed

                    Logger.debug( "yielding with '{data}'".format( data=data_dict ) )
                    yield data_dict

        except Exception as exception: raise RuntimeError( "error retrieving data with '{error}'".format( error=exception ) )

    @staticmethod
    def parse_stream_data( value ):

        assert isinstance( value, str )

        return_value = None

        Logger.debug( "received value '{value}' to parse".format( value=value ) )

        if re.match( ".*,[0-9]{3}$", value ) is not None: return_value = int( value.replace( ",", "" ) )
        elif re.match( "^[0-9]{10}$", value ) is not None: return_value = str( datetime.datetime.fromtimestamp( int( value ) ) )
        elif re.match( "^[+-]?[0-9]{1,8}$", value ) is not None: return_value = int( value )
        elif re.match( "^[+-]?[0-9]{1,8}%$", value ) is not None: return_value = int( value )
        elif re.match( "^[+-]?[0-9]{1,8}\.[0-9]{1,5}$", value ) is not None: return_value = float( value.replace( "%", "" ) )
        elif re.match( "^[+-]?[0-9]{1,8}\.[0-9]{1,5}%$", value ) is not None: return_value = float( value.replace( "%", "" ) )
        else: raise RuntimeError( "value not in expected format" ) # TODO: change for proper exception

        Logger.debug( "returning '{output}' from '{input}'".format( output=return_value, input=value ) )

        return return_value

    # yahoo finance yql symbol instant and historic stats
    def __get_symbol_data( symbol, start_date=None, end_date=None ):
        date_format = "%Y-%m-%d"

        if start_date and end_date:
            table = "historicaldata"
            datestring = ( "and%20startDate%20=%20%22{start}%22%20"
                           "and%20endDate%20=%20%22{end}%22" ).format( start=start_date.strftime( date_format ),
                                                                       end=end_date.strftime( date_format ) )
        elif start_date and not end_date: raise RuntimeError( "here be dragons..." )
        else:
            table = "quotes"
            datestring = ""

        try:
            response = Retriever.blocking_get( "https://query.yahooapis.com/v1/public/yql?"
                                               "q=select%20*%20from%20yahoo.finance.{table}%20where%20symbol%20=%20%22{symbol}%22"
                                               "{datestring}"
                                               "&env=store://datatables.org/alltableswithkeys"
                                               "&format=json".format( table=table, symbol=symbol, datestring=datestring ),
                                               timeout=5 )
            return json.loads( response )
        except Exception as exception: raise RuntimeError( exception )

    @staticmethod
    def get_symbol_data( symbol ):
        return_dict = {}

        response = MarketData.__get_symbol_data( symbol )

        try:
            for key, value in response[ "query" ][ "results" ][ "quote" ].items():
                parsed = MarketData.parse_symbol_data( key, value )
                if parsed is not None: return_dict[ key ] = parsed # delete if returning None
        except Exception as exception: raise RuntimeError( "json not in expected format with '{json}'".format( json=response ) )

        return return_dict

    @staticmethod
    def get_symbol_data_at_date( symbol, start_date, end_date ):
        return_list = []

        response = MarketData.__get_symbol_data( symbol, start_date, end_date )

        try:
            for item in response[ "query" ][ "results" ][ "quote" ]:
                list_dict = {}
                for key, value in item.items():
                    parsed = MarketData.parse_symbol_data( key, value )
                    if parsed is not None: list_dict[ key ] = parsed # delete if returning None
                return_list.append( list_dict )
        except Exception as exception: raise RuntimeError( "json not in expected format with '{json}'".format( json=response ) )

        return return_list

    @staticmethod
    def parse_symbol_data( key, value ):
        return_value = None

        if value is None: pass
        else:
            if key not in [ name for name, options in YQLSymbolOptionsList.__members__.items() ]: pass
            else:
                if YQLSymbolOptionsList[ key ].value[ "type" ] is None: pass
                elif YQLSymbolOptionsList[ key ].value[ "type" ] is str: return_value = str( value )
                elif YQLSymbolOptionsList[ key ].value[ "type" ] is float:
                    parsed_float = float( value.replace( "%", "" ) )
                    if math.isnan( parsed_float ) or math.isinf( parsed_float ): pass
                    else: return_value = parsed_float
                elif YQLSymbolOptionsList[ key ].value[ "type" ] is int: return_value = int( value.replace( "%", "" ) )
                else: raise RuntimeError( "option not in expected format with key '{key}' and value {value}".format( key=key, value=value ) )

        return return_value


class Currency():
    __updated = False

    @staticmethod
    def is_updated(): return Currency.__updated

    @staticmethod
    def update():
        # TODO: make this into a class that's updated on a schedule # need to think about race problems that could casue :|
        # also, look to use https://www.ecb.europa.eu/stats/eurofxref/eurofxref-daily.xml as it's updated more frequently
        xrates.install( "money.exchange.SimpleBackend" )
        Logger.debug( "exchange rates backend installed" )

        xrates.base = "USD" # TODO: change to config
        try:
            response = Retriever.blocking_get( "http://api.fixer.io/latest?base=USD", timeout=10 )
            parsed_json = json.loads( response )
        except Exception as exception: raise RuntimeError( "error parsing json with '{error}'".format( error=exception ) )

        try:
            for key, value in parsed_json[ "rates" ].items():
                xrates.setrate( key, value )
                Logger.debug( "updated {currency} to '{rate}' against base".format( currency=key, rate=value ) )
        except Exception as exception: raise RuntimeError( "json not in expected format" )

        Currency.__updated = True

        Logger.debug( "exchange rates updated" )

    @staticmethod
    def start():
        while True:
            Currency.update()
            if Currency.is_updated():
                Logger.debug( "rates updated" )
                break
            else:
                Logger.debug( "unable to fetch new rates, sleeping for 30 seconds before retrying" )
                time.sleep( 30 )
        Scheduler.add( Currency.update, schedule={ "minute": "1" } )
        Logger.debug( "rates update scheduled" )


class Intelligence():
    __market_risers_uuid = None

    class MarketRisers():
        __following = []
        __followed = {}

        @staticmethod
        def run(): # TODO: strict runtime of under 30 seconds
            gainers_list = list()

            # TODO: put in __followed list pruning for older than 24 hours or sth.

            for market in list( MarketsList ):

                if MarketData.is_market_open( market ):
                    try:
                        gainers_list += [ gainer for gainer in MarketData.list_gainers( market ) ]
                    except Exception as exception:
                        Logger.error( "unable to retrieve gainers for '{market}' with '{error}'".format( market=market, error=exception ) )

            if len( gainers_list ) < 1:
                Logger.debug( "no gainers found" )
            else:
                gainers_list = MarketData.remove_gainers_below_value( gainers_list, Config.MARKET_GAINERS_RATE_THRESHOLD )

                for gainer in gainers_list:

                    if gainer[ "symbol" ] in Intelligence.MarketRisers.__following:
                        Logger.debug( "skipping '{symbol}' as already following".format( symbol=gainer[ "symbol" ] ) )
                        continue

                    # TODO: not sure this works as _followed's a dict! maybe need _folloed.keys() ??
                    if gainer[ "symbol" ] in Intelligence.MarketRisers.__followed:
                        if ( Intelligence.MarketRisers.__followed[ gainer[ "symbol" ] ] + Config.SYMBOL_FOLLOWER_BACKOFF_THRESHOLD ) > datetime.datetime.utcnow():
                            Logger.debug( "skipping '{symbol}' as listed in following history".format( symbol=gainer[ "symbol" ] ) )
                            continue
                        else:
                            Intelligence.MarketRisers.__followed.pop( gainer[ "symbol" ] )

                    Intelligence.MarketRisers.__following.append( gainer[ "symbol" ] )
                    Intelligence.MarketRisers.__followed[ gainer[ "symbol" ] ] = datetime.datetime.utcnow()
                    Scheduler.add( Intelligence.MarketRisers.__follow_symbol, args=[ gainer[ "symbol" ], gainer[ "exchange" ] ], first_run_seconds=random.randrange( 10, 30, 1 ), grace_seconds=30 ) # GIL sadness, too much running at once

        @staticmethod
        def __test_symbol_usable( symbol, last_trade_datetime, last_trade_price, open, current_volume, historical_volumes ):

            if ( datetime.datetime.utcnow() - Config.SYMBOL_FOLLOWER_STALE_THRESHOLD ) > last_trade_datetime:
                Logger.debug( "stale symbol '{symbol}' detected with last trade at '{last}'".format( symbol=symbol, last=str( last_trade_datetime ) ) )
                return False

            change = ( float( last_trade_price ) / float( open ) ) - 1.0
            if change <= Config.SYMBOL_FOLLOWER_CHANGE_THRESHOLD:
                Logger.debug( "symbol '{symbol}' movement under threshold with '{change}'".format( symbol=symbol, change=change ) )
                return False

            if current_volume <= Config.SYMBOL_FOLLOWER_VOLUME_LOWER_LIMIT:
                Logger.debug( "dropping '{symbol}' with not enough volume '{volume}'".format( symbol=symbol, volume=current_volume ) )
                return False

# this fires too often to test properly, reenable for prod.
#            for volume in historical_volumes[ -3:-1 ]:
#                if volume <= Config.SYMBOL_FOLLOWER_VOLUME_LOWER_LIMIT: continue
#                else:
#                    if ( 1 - Config.SYMBOL_FOLLOWER_VOLUME_THRESHOLD ) <= ( current_volume / volume ) <= ( 1 + Config.SYMBOL_FOLLOWER_VOLUME_THRESHOLD ):
#                        Logger.debug( "dropping '{symbol}' as '{current_volume}' / '{volume}' outside volume change threshold".format( symbol=symbol, current_volume=current_volume, volume=volume ) )
#                        return False

            # TODO: pull split information from yahoo and test <- might be unreliable

            return True

        @staticmethod
        def __test_symbol_tick_buy_time_to_profit( symbol, ticks ):

            time_took = ticks.keys()[ -1 ] - ticks.keys()[ -5 ]
            percent_change = ticks.values[ -1 ] / ticks.values[ -5 ]

            cost = Config.TRADE_COST_BUY + Config.TRADE_COST_SELL
            price = Decimal( ticks.values[ -1 ] )

            profit_percent = price / ( price + Decimal( float( cost ) ) ) # quantity factored out

            minutes_to_profit = ( ( percent_change / float( profit_percent ) ) * time_took ).seconds / 60

            return math.ceil( minutes_to_profit )

        @staticmethod
        def __test_symbol_tick_buy( symbol, data, ticks ):
            ### TODO: turn everything right down and slowly bring up
            ### TODO: don't return none for all sources, change to confidence level instead?

            if ( len( ticks[ "price" ] ) < 1 ):
                Logger.debug( "not enough ticks gathered for '{symbol}' with length '{length}'".format( symbol=symbol, length=len( ticks[ "price" ] ) ) )
                return None

            # TODO: check interpolation schemes for best, maybe use one that exaggerates deviation??
            # TODO: use amount of steps interpolated in confidence number??
            resampled_prices = ticks[ "price" ].resample( "1min" ).interpolate()[ -10: ]

            # TODO: not sure if this actually does anything with the step change above...? ... testing ...
            if len( resampled_prices ) < 10:
                Logger.debug( "not enough samples interpolated from '{symbol}' with '{samples}' from '{source}'".format( symbol=symbol, samples=len( resampled_prices ), source=len( ticks[ "price" ] ) ) )
                return None

            # TODO: needs testing with the resolution change above - use intervals? and peaks and troughs?
            if Utils.detect_flapping( resampled_prices, 0.2, 3 ):
                Logger.debug( "flapping detected on '{symbol}' with values '{values}'".format( symbol=symbol, values=resampled_prices ) )
                return None

            # TODO: this needs a fail counter as it'll be too sensitive
            if Utils.detect_downturn( resampled_prices, 4 ):
                Logger.debug( "downturn detected with '{values}'".format( values=resampled_prices ) )
                return None

            incline_rate = resampled_prices.values[ -1 ] / resampled_prices.values[ 0 ]
            if  incline_rate < 0.3:
                Logger.debug( "symbol '{symbol}' not raising quick enough with rate '{rate}'".format( symbol=symbol, rate=incline_rate ) )
                return None

            # TODO: start to build confidence level using this??
            time_to_profit = Intelligence.MarketRisers.__test_symbol_tick_buy_time_to_profit( symbol, resampled_prices )
            if time_to_profit > 20:
                Logger.debug( "symbol '{symbol}' won't turn a profit quickly enough with '{time}' minutes ".format( symbol=symbol, time=time_to_profit ) )
                return None

            # TODO: verify resampled slope matches independent source against external source - use for confidence level ?

            # TODO: test confidence level which has negative or positive points scored against int( 0 ) depending on good numbers for functions above

            # TODO: check how close we are to the end of the day

            return 1.0

        @staticmethod
        def __test_symbol_tick_sell( symbol, data, ticks, bought_at ): # TODO: this is only triggered on ticks, so could miss the timeout :(

            if ( bought_at + Config.SYMBOL_FOLLOWER_SELL_TIMELIMIT ) < datetime.datetime.utcnow(): return 1.0

            resampled_prices = ticks[ "price" ].resample( "1min" ).interpolate()[ -10: ]

            # TODO: not sure if this actually does anything with the step change above...? ... testing ...
            if len( resampled_prices ) < 10: # this shouldn't happen, throw error
                Logger.debug( "not enough samples interpolated from '{symbol}' with '{samples}' from '{source}'".format( symbol=symbol, samples=len( resampled_prices ), source=len( ticks[ "price" ] ) ) )
                return 1.0

            # TODO: needs testing with the resolution change above - use intervals? and peaks and troughs?
            if Utils.detect_flapping( resampled_prices, 0.2, 3 ):
                Logger.debug( "flapping detected on '{symbol}' with values '{values}'".format( symbol=symbol, values=resampled_prices ) )
                return 1.0

            # TODO: this needs a fail counter as it'll be too sensitive
            if Utils.detect_downturn( resampled_prices, 2 ):
                Logger.debug( "downturn detected with '{values}'".format( values=resampled_prices ) )
                return 1.0

            # check slope flattening out

            # use similar checks to buy function ie. flapping, leveling out, etc.

            # TODO: check how close we are to the end of the day

            return None

        @staticmethod
        def __follow_symbol_add_tick( line, ticks ):
            for key, value in { "a00": "ask", "b00": "bid", "l10": "price", "v00": "volume" }.items():
                if key in line.keys():
                    ticks[ value ] = ticks[ value ].append(
                        pandas.Series( { pandas.Timestamp( datetime.datetime.utcnow() ): line[ key ] } ),verify_integrity=True )
            return ticks

        @staticmethod
        def __follow_symbol_buy_sell_logic( symbol, bought_at, sold_at, data, ticks ):
            if len( ticks[ "bid" ].values ) < 1 and len( ticks[ "price" ].values < 1 ): # TODO: use all() here ?
                Logger.debug( "not enough tick data to work with" )
            else:
                if sold_at is None:
                    # TODO: not sure if "bid" is correct here, needs research/testing
                    if bought_at is None:
                        confidence = Intelligence.MarketRisers.__test_symbol_tick_buy( symbol, data, ticks )
                        if confidence is not None:
                            if OrderBook.buy( symbol, ticks[ "bid" ].values[ -1 ], confidence ):
                                bought_at = datetime.datetime.utcnow()
                                Publisher.send_balance( OrderBook.get_balance() )
                                Publisher.send_annotation( symbol, datetime.datetime.utcnow(), "B" )
                                Logger.debug( "issued buy order for '{symbol}' at '{price}' with confidence '{confidence}'".format( symbol=symbol, price=ticks[ "bid" ].values[ -1 ], confidence=confidence ) )
                    else:
                        confidence = Intelligence.MarketRisers.__test_symbol_tick_sell( symbol, data, ticks, bought_at )
                        if confidence is not None:
                            if OrderBook.sell( symbol, ticks[ "bid" ].values[ -1 ], confidence ):
                                sold_at = datetime.datetime.utcnow()
                                Publisher.send_balance( OrderBook.get_balance() )
                                Publisher.send_annotation( symbol, datetime.datetime.utcnow(), "S" )
                                Logger.debug( "issued sell order for '{symbol}' at '{price}' with quantity '{quantity}'".format( symbol=symbol, price=ticks[ "bid" ].values[ -1 ], quantity=confidence ) )

            return bought_at, sold_at

        @staticmethod
        def __follow_symbol( symbol, exchange ): # break out into streaming function and logic function
            assert isinstance( symbol, str )

            try:
                symbol_data = MarketData.get_symbol_data( symbol )
                symbol_historical = MarketData.get_symbol_data_at_date( symbol,
                                                                        datetime.datetime.utcnow() - Config.SYMBOL_FOLLOWER_HISTORICAL_FROM,
                                                                        datetime.datetime.utcnow() - Config.SYMBOL_FOLLOWER_HISTORICAL_TO )

                if not all( key in symbol_data for key in [ "LastTradeTime", "LastTradeDate", "LastTradePriceOnly", "Open" ] ):
                    Logger.debug( "dropping '{symbol}' source '{exchange}' as incorrect data '{data}' for test_usable".format( symbol=symbol, exchange=exchange, data=str( symbol_data ) ) )
                else:
                    last_trade_datetime = datetime.datetime.strptime( "{date} {time}".format( date=symbol_data[ "LastTradeDate" ],
                                                                                              time=symbol_data[ "LastTradeTime" ] ),
                                                                      "%m/%d/%Y %I:%M%p" ) - datetime.timedelta( hours=exchange.value[ "offset" ] )
                    volumes = [ data[ "Volume" ] for data in symbol_historical ]
                    if Intelligence.MarketRisers.__test_symbol_usable(
                            symbol, last_trade_datetime, symbol_data[ "LastTradePriceOnly" ], symbol_data[ "Open" ], symbol_data[ "Volume" ], volumes ):

                        Archive.add_symbol_snapshot( exchange, symbol, datetime.datetime.utcnow(), symbol_data )
                        Archive.add_symbol_historical( exchange, symbol, datetime.datetime.utcnow(), symbol_historical ) # TODO: is this really required?
                        Logger.debug( "snapshot and historical data archived" )

                        started_at = datetime.datetime.utcnow(); bought_at = None; sold_at = None

                        ticks = { "ask": pandas.Series(), "bid": pandas.Series(), "price": pandas.Series(), "volume": pandas.Series() }

                        for line in MarketData.stream_symbol_data( symbol, list( YFStreamerOptionsList ) ):
                            Logger.debug( "received tick for '{symbol}' with data '{data}'".format( symbol=symbol, data=line ) )

                            Archive.add_symbol_tick( exchange, symbol, datetime.datetime.utcnow(), line )
                            Logger.debug( "tick data archived" )

                            if ( started_at + Config.SYMBOL_FOLLOWER_MAX_RUNTIME ) < datetime.datetime.utcnow():
                                Logger.debug( "max runtime exceeded with start time '{start}'".format( start=str( started_at ) ) )
                                break

                            ticks = Intelligence.MarketRisers.__follow_symbol_add_tick( line, ticks )
                            Logger.debug( "ticks updated with line '{line}'".format( line=line ) )

                            if sold_at is None:
                                bought_at, sold_at = Intelligence.MarketRisers.__follow_symbol_buy_sell_logic( symbol, bought_at, sold_at, symbol_data, ticks )

                        Logger.debug( "finished following symbol '{symbol}'".format( symbol=symbol ) )

                        if bought_at is not None and sold_at is None:
                            if len( ticks[ "bid" ].values ) < 1: OrderBook.sell( symbol )
                            else: OrderBook.sell( symbol, ticks[ "price" ].values[ -1 ] ) # TODO: this needs thought for accuracy

                            Publisher.send_annotation( symbol, datetime.datetime.utcnow(), "SELL" )
                            Logger.error( "'{symbol}' buy order issued but stream died, issuing emergency sell".format( symbol=symbol ) )

            except Exception as exception:
                Logger.debug( "error following symbol with '{error}' and '{traceback}'".format( error=exception, traceback=traceback.extract_tb( exception.__traceback__ ) ) )

            Intelligence.MarketRisers.__following.remove( symbol )

        @staticmethod
        def list_following(): return Intelligence.MarketRisers.__following

        @staticmethod
        def list_followed(): return Intelligence.MarketRisers.__followed


    @staticmethod
    def start():
        Intelligence.__market_risers_uuid = Scheduler.add( Intelligence.MarketRisers.run, schedule={ "minute": "*/5" }, first_run_seconds=1, grace_seconds=10 )
        Logger.debug( "marketrisers schedule added" )

    @staticmethod
    def stop():
        Scheduler.remove( Intelligence.__market_risers_uuid, force_stop=True )
        Logger.debug( "marketrisers schedule removed" )


class OrderBook(): # need to consider sequential access to prevent race conditions, queue?
    __balance = None

    __active = None # { timestamp, symbol, price, quantity }
    __history = None

    @staticmethod
    def get_balance(): return OrderBook.__balance

    @staticmethod
    def get_symbol( symbol ): return OrderBook.__get_order_by_symbol( symbol )

    @staticmethod
    def __get_order_by_symbol( symbol ):
        for order in OrderBook.__active:
            if order[ "symbol" ] == symbol: return order
        return None

    @staticmethod
    def __is_active( symbol ):
        if not OrderBook.__get_order_by_symbol( symbol ): return False
        else: return True

    @staticmethod
    def list_active(): return OrderBook.__active

    @staticmethod
    def list_history(): return OrderBook.__history

    @staticmethod
    def buy( symbol, quote, confidence=0.0 ):
        Logger.debug( "buy order received against '{symbol}' at '{quote}' with confidence {confidence}".format( symbol=symbol, quote=quote, confidence=confidence ) )

        if OrderBook.__balance < 1: raise RuntimeError( "orderbook balanace is 0" ) # TODO: change to config and higher than ~100

        if OrderBook.__is_active( symbol ): raise RuntimeError( "symbol already active" )

        available_to_spend = OrderBook.__balance * Decimal( Config.ORDERBOOK_MAXIMUM_SPEND ) * Decimal( confidence )
        amount_to_buy = math.floor( available_to_spend / Decimal( quote ) )

        if amount_to_buy < Config.ORDERBOOK_MINIMUM_ORDER:
            Logger.warn( "below minimum '{config}' with amount '{amount}'".format( amount=amount_to_buy, config=Config.ORDERBOOK_MINIMUM_ORDER ) )
            return False

        price = amount_to_buy * quote
        cost = Decimal( price ) + Config.TRADE_COST_BUY

        OrderBook.__balance -= cost
        Logger.warn( "confirmed buy order for '{symbol}' at '{price}' for '{amount}' with buying fee '{fee}' costing '{cost}', new balance is '{balance}'".format(
            symbol=symbol, price=quote, amount=amount_to_buy, fee=Config.TRADE_COST_BUY, cost=cost, balance=OrderBook.__balance ) )

        OrderBook.__active.append( { "timestamp": datetime.datetime.utcnow(), "symbol": symbol, "buy_price": quote, "quantity": amount_to_buy } )
        Logger.debug( "order added to active list for '{symbol}'".format( symbol=symbol ) )

        return True

    @staticmethod
    def sell( symbol, quote=None, quantity=1.0 ):
        Logger.debug( "sell order received against '{symbol}' at '{quote}' with quantity {quantity}".format( symbol=symbol, quote=quote, quantity=quantity ) )

        if not OrderBook.__is_active( symbol ): raise RuntimeError( "'{symbol}' not found in active orders".format( symbol=symbol ) )

        order = OrderBook.__get_order_by_symbol( symbol )

        if quote is None:
            quote = order[ "price" ]
            if quote is None: raise RuntimeError( "cannot find '{symbol}' in active orders".format( symbol=symbol ) )
            Logger.error( "no quote provided for '{symbol}' using previous value '{previous}'".format( symbol=symbol, previous=quote ) )

        previous_price = order[ "quantity" ] * order[ "buy_price" ]
        current_price = order[ "quantity" ] * quote
        profit = Decimal( current_price ) - Decimal( previous_price ) - ( Config.TRADE_COST_BUY + Config.TRADE_COST_SELL )

        OrderBook.__active.remove( order )

        order[ "moved" ] = datetime.datetime.utcnow()
        order[ "sale_price" ] = quote
        order[ "profit" ] = profit

        OrderBook.__history.append( order )
        Logger.debug( "'{order}' moved from active to history".format( order=order ) )

        OrderBook.__balance += Decimal( current_price ) - Config.TRADE_COST_SELL
        Logger.warn( "confirmed sell order for '{symbol}' at '{price}' with selling fee '{fee}' giving profit '{profit}' and new balance is '{balance}'".format(
            symbol=symbol, price=quote, fee=Config.TRADE_COST_SELL, profit=profit, balance=OrderBook.__balance ) )

        return True

    @staticmethod
    def sell_all():
        for item in OrderBook.__active:
            OrderBook.sell( item[ "symbol" ] )

    @staticmethod
    def reset_balance(): OrderBook.__balance = Config.ORDERBOOK_SEED_BUDGET

    @staticmethod
    def start():
        OrderBook.__balance = Config.ORDERBOOK_SEED_BUDGET

        OrderBook.__active = list() # { symbol, volume, quote }
        OrderBook.__history = list()

    @staticmethod
    def stop():
        if len( OrderBook.__active ) > 0:
            Logger.warn( "stop called but buy orders active" )

            OrderBook.sell_all()
            Logger.debug( "general sell order issued" )


class Logger():
    """static logging class with magical abbreviation for lists & dicts (and pretty possible formatting)"""

    @staticmethod
    def start():
        logging_format = logging.Formatter( "%(levelname)s: %(asctime)s - %(threadName)s->%(filename)s:%(lineno)d->%(funcName)s\n"
                                            "%(levelname)s: %(message)s\n" )

        logging_stdout = logging.StreamHandler( sys.stdout )
        logging_stdout.setFormatter( logging_format )
        logging_stdout.setLevel( logging.WARNING )
        logging.getLogger().addHandler( logging_stdout )

        logging_file = logging.handlers.RotatingFileHandler(
            filename = Config.LOGGING_PATH, backupCount = 3, maxBytes=( 1024 * 1024 * 500 ), mode="" )
        logging_file.setFormatter( logging_format )
        logging_file.setLevel( logging.DEBUG )
        logging.getLogger().addHandler( logging_file )

        if os.path.isfile( Config.LOGGING_PATH ): logging_file.doRollover()

        logging.getLogger().setLevel( logging.DEBUG )

    @staticmethod
    def __get_logger(): return logging.getLogger( Config.LOGGING_NAME )

    @staticmethod
    def __cast_to_string( message ):

        assert isinstance( message, ( str, list, dict ) )

        if isinstance( message, str ): pass
        elif isinstance( message, list ): message = str( message ) # TODO: prettyprint?
        elif isinstance( message, dict ): message = str( message ) # TODO: prettyprint?
        else: raise RuntimeError( "here be dragons" )

        return message

    @staticmethod
    def abbrev( message, limit=75, force=False ): # possible name clash using full "abbreviation" name so abbreviating ^_^

        assert isinstance( message, ( str, list, dict ) )

        message = Logger.__cast_to_string( message )

        if not force and not Config.ABBREVIATE_DEBUG_OUTPUT: return message
        else:
            if len( message ) < ( ( limit * 2 ) + 5 ): return message
            else: return message[:limit]  + " ... " + message[-limit:]

    @staticmethod
    def set_level( level ):
        Logger.__get_logger().setLevel( level )
        Logger.debug( "changed level to {level}".format( level=str( level ) ) )

    @staticmethod
    def debug( message, abbreviate=True ):

        assert isinstance( message, ( str, list, dict ) )
        assert isinstance( abbreviate, bool )

        message = Logger.__cast_to_string( message )

        if abbreviate: message = Logger.abbrev( message )

        Logger.__get_logger().debug( message )

    @staticmethod
    def info( message, abbreviate=True ):

        assert isinstance( message, ( str, list, dict ) )
        assert isinstance( abbreviate, bool )

        message = Logger.__cast_to_string( message )

        if abbreviate: message = Logger.abbrev( message )

        Logger.__get_logger().info( message )

    @staticmethod
    def warn( message, abbreviate=True ):

        assert isinstance( message, ( str, list, dict ) )
        assert isinstance( abbreviate, bool )

        message = Logger.__cast_to_string( message )

        if abbreviate: message = Logger.abbrev( message )

        Logger.__get_logger().warning( message )

    @staticmethod
    def error( message, abbreviate=True ):

        assert isinstance( message, ( str, list, dict ) )
        assert isinstance( abbreviate, bool )

        message = Logger.__cast_to_string( message )

        if abbreviate: message = Logger.abbrev( message )

        Logger.__get_logger().error( message )

    @staticmethod
    def critical( message, abbreviate=True ):

        assert isinstance( message, ( str, list, dict ) )
        assert isinstance( abbreviate, bool )

        message = Logger.__cast_to_string( message )

        if abbreviate: message = Logger.abbrev( message )

        Logger.__get_logger().critical( message )


class Scheduler():

    __scheduler_reference = None
    __active_jobs_list = None

    @staticmethod
    def __list_search_by_jobid( id ):
        for item in Scheduler.__active_jobs_list:
            if item[ "job" ].id == id:
                return item

        return None

    @staticmethod
    def __list_search_by_uuid( uuid ):
        for element in Scheduler.__active_jobs_list:
            if element[ "uuid" ] is uuid: return element
        return None

    @staticmethod
    def __list_generate_unique_uuid():
        fail_count = 0
        while fail_count <= 4: # change to config setting
            uuid = Utils.uuid_generator()

            if Scheduler.__list_search_by_uuid( uuid ) is None: return uuid
            else:
                Logger.critical( "found clashing uuid in list" )
                fail_count += 1

        raise RuntimeError( "it took more than 5 attempts to retrieve a uuid" )

    @staticmethod
    def __list_add( uuid, job, schedule=None ):
        if Scheduler.__list_search_by_uuid( uuid ) is None:
            Scheduler.__active_jobs_list.append( { "uuid": uuid, "job": job, "schedule": schedule } )
            Logger.debug( "uuid '{uuid}' added to list".format( uuid=uuid ) )
        else: raise RuntimeError( "the uuid '{uuid}' was already present".format( uuid=uuid ) )

    @staticmethod
    def __list_remove( uuid ): raise NotImplementedError()

    @staticmethod
    def __callback( event ):
        if event.code == EVENT_JOB_EXECUTED:
            list_item = Scheduler.__list_search_by_jobid( event.job_id )
            if not list_item: Logger.debug( "callback received with job id '{jobid}' but not in list".format( jobid=event.job_id ) )
            else:
                if list_item[ "schedule" ] is None:
                    Scheduler.__active_jobs_list.remove( list_item )
        elif event.code == EVENT_JOB_ERROR: Logger.error( str( event ) )

    @staticmethod
    def add( func, schedule=None, args=list(), kwargs=dict(), first_run_seconds=None, grace_seconds=None ):
        uuid = Scheduler.__list_generate_unique_uuid()
        Logger.debug( "received uuid '{uuid}'".format( uuid=uuid ) )

        scheduler_args = { "id": uuid, "args": args, "kwargs": kwargs,
                            "coalesce": True, "misfire_grace_time": 10, "max_instances": 1 }

        Logger.debug( "passing arguments '{args}' to scheduler".format( args=scheduler_args ) )

        if schedule:
            scheduler_args[ "trigger" ] = CronTrigger( **schedule )
            Logger.debug( "using schedule '{schedule}'".format( schedule=schedule ) )

        if first_run_seconds:
            when = datetime.datetime.utcnow() + datetime.timedelta( seconds = first_run_seconds )
            scheduler_args[ "next_run_time" ] = when
            Logger.debug( "first run scheduled for '{when}'".format( when=when ) )

        if grace_seconds:
            scheduler_args[ "misfire_grace_time" ] = grace_seconds
            Logger.debug( "allow '{grace}' seconds to run".format( grace=grace_seconds ) )

        Scheduler.__list_add( uuid, Scheduler.__scheduler_reference.add_job( func, **scheduler_args ), schedule )
        Logger.debug( "job added with uuid '{uuid}', function '{func}' and args '{args}'".format( uuid=uuid,
                                                                                                  func=str( func ),
                                                                                                  args=str( scheduler_args ) ) )

        return uuid

    @staticmethod
    def remove( uuid, force_stop=False ): raise NotImplementedError() # don't remove if running!

    @staticmethod
    def start():
        Scheduler.__active_jobs_list = list()

        Scheduler.__scheduler_reference = BackgroundScheduler( {
            'apscheduler.executors.default': {
                'class': 'apscheduler.executors.pool:ThreadPoolExecutor',
                'max_workers': Config.SCHEDULER_MAX_THREADS } } )
        Scheduler.__scheduler_reference.add_listener( Scheduler.__callback )
        Scheduler.__scheduler_reference.start()

    @staticmethod
    def stop( forced=False ):
        if forced: Scheduler.__scheduler_reference.shutdown( wait=False )
        else: Scheduler.__scheduler_reference.shutdown( wait=True )

        Scheduler.__scheduler_reference = None

    @staticmethod
    def list_active_jobs(): # TODO: fix active_jobs and get_jobs should be the same see callback
        return_list = []
        for item in Scheduler.__active_jobs_list: return_list.append( item )
        return return_list


class Utils():

    @staticmethod
    def random_sleep( minimum, maximum, step=1 ): time.sleep( random.randrange( minimum, maximum, step ) )

    @staticmethod
    def detect_downturn( values, down_count ):
        count = 0
        for index, value in enumerate( values ):
            if count == down_count: break

            if value < values.values[ -1 ]: count += 1

        if count == down_count: return True
        else: return False

    @staticmethod
    def detect_flapping( values, change_threshold, change_count ): # this could do with an optimisation pass think speed/space
        processed_values = []
        for index, value in enumerate( values.iteritems() ):
                previous_value = values.values[ index - 1 ]
                value_threshold = previous_value * change_threshold

                Logger.debug(
                    "from '{old}' to '{new}' with '{threshold}'".format( old=previous_value, new=value, threshold=value_threshold ) )

                if previous_value > value[ 1 ] + value_threshold:
                        processed_values.append( 0 )
                        continue
                elif previous_value < value[ 1 ] - value_threshold:
                        processed_values.append( 1 )
                        continue

        matches = 0
        for index, value in enumerate( processed_values ):
                if matches == change_count: break

                previous_value = processed_values[ index - 1 ]
                if previous_value is not None and value is not previous_value: matches += 1

        if matches == change_count: return True
        else: return False

    @staticmethod
    def uuid_generator(): return str( uuid.uuid4() ) # guaranteed by fair dice roll :)

    @staticmethod
    def dict_combine( first, second ):
        # lossy, with second dict taking precedence, needs testing
        # should probably change to throwing an exception is there's a clash?

        assert isinstance( first, dict )
        assert isinstance( second, dict )

        return dict( chain( first.items(), second.items() ) )


class Requests():
    @staticmethod
    def blocking_request( method, url, data=None, timeout=None, Local=False ): # TODO: method should really be an enum here
        buffer = io.BytesIO()
        connection = pycurl.Curl()

        connection.setopt( connection.URL, url )
        connection.setopt( connection.FAILONERROR, True )
        connection.setopt( connection.WRITEDATA, buffer )
        connection.setopt( pycurl.CONNECTTIMEOUT, 3 )
        connection.setopt( pycurl.NOSIGNAL, 1 )
#        if not local: conncetion.setopt( conncetion.PROXY, "http://{host}:{port}".format( host=Config.PROXY_HOST, port=Config.PROXY_PORT ) )
        connection.setopt( connection.HTTPHEADER, [ "Accept-Charset: UTF-8", "Connection: close" ] )

        if method == "post" and data is not None:
            if isinstance( data, dict ):
                connection.setopt( connection.POSTFIELDS, "&".join( [ "{key}={value}".format( key=key, value=value ) for key, value in data.items() ] ) )
            elif isinstance( data, str ):
                connection.setopt( connection.POSTFIELDS, data )
            elif isinstance( data, bytes ):
                connection.setopt( connection.POSTFIELDS, str( data ) )
            else:
                raise RuntimeError( "here be dragons" )

        if timeout: connection.setopt( pycurl.TIMEOUT, timeout )

        try:
            connection.perform()
            connection.close()

            return buffer.getvalue().decode( "utf-8" ) # TODO: work this out from headers
        except Exception as exception: raise RuntimeError( "exception" )

class Retriever():
    @staticmethod
    def blocking_get( url, timeout=None ): return Requests.blocking_request( "get", url, timeout=timeout )

    @staticmethod
    def streaming_get_by_line( host, port, url, timeout=None, http_version="1.1" ):
        try:
            connection = socket.create_connection( ( host, port ) )
            if timeout: connection.settimeout( timeout )
            Logger.debug( "socket opened" )

#            connection.sendall( str.encode( "CONNECT {host}:{port} HTTP/1.1" ) )
#
#            time.sleep( 0.5 )
#
#            proxy_result = connection.recv( 4096 ) # TODO: check for "HTTP/1.0 200 Connection established"

            connection.sendall( str.encode( "GET {url} HTTP/{http_version}\n\n".format( url=url, http_version=http_version ) ) )
            Logger.debug( "request sent" )

            while True:
                buffer = connection.recv( 4096 )
                Logger.debug( "recieved partial response '{buffer}'".format( buffer=str( buffer ) ) )

                if not buffer: # EOF detected
                    Logger.debug( "EOF reached on socket" )
                    break

                for line in buffer.decode().splitlines(): yield line

            Logger.debug( "finished processing lines" )

            connection.close()
            Logger.debug( "connection closed" )

        except Exception as exception: raise RuntimeError( "error retrieving data with '{error}'".format( error=exception ) )

class Sender():
    @staticmethod
    def blocking_post( url, data=None, timeout=None ): return Requests.blocking_request( "post", url, data=data, timeout=timeout )


class Archive():
    # TODO: look into making this more intelligent/coupled with sqlalchemy
    # TODO: this should probably be an instance class... needs thought

    # instance class, possibly abstracted ?? # look at using/with syntax for auto cleanup
#    class Elasticsearch
#    class Postgres

    @staticmethod
    def __elasticsearch_put( index, body, timestamp=datetime.datetime.utcnow(), type="none" ):

        if not "timestamp" in body.keys(): body[ "timestamp" ] = timestamp

        reference = Elasticsearch()

        #reference.indices.create( index=index, ignore=400 ) # ignore IndexAlreadyExistsException

        try:
            reference.create( index=index, doc_type=type, body=body, refresh=True )
        except Exception as exception: Logger.critical( str( exception ) )

    @staticmethod
    def __connect():
        connection =  psycopg2.connect( connection_factory=psycopg2.extras.LoggingConnection,
                                        host = Config.DATASTORE_POSTGRES_HOST,
                                        database = Config.DATASTORE_POSTGRES_DB,
                                        user =  Config.DATASTORE_POSTGRES_USER,
                                        password = Config.DATASTORE_POSTGRES_PASS)

        connection.initialize( logging.getLogger() )

        return connection

    @staticmethod
    def __disconnect( connection ):
        connection.close()

    @staticmethod
    def __query( connection, query, parameters = {} ):
        cursor = connection.cursor()
        cursor.execute( query, parameters )
        return cursor

    @staticmethod
    def __results( cursor ):
        yield cursor.fetchone()

    @staticmethod
    def __simple_insert( table, columns, values ):
        connection = Archive.__connect()
        Archive.__query( connection,
                         """
                             INSERT INTO {table} ({columns}) VALUES (%(values)s);
                         """.format( table=table, columns=",".join( columns ) ),
                         {
                             "values": ",".join( values ) # TODO: change to tupples see. Tuples adaptation at http://initd.org/psycopg/docs/usage.html#adapt-date
                         } )
        connection.commit()
        Archive.__disconnect( connection )

    @staticmethod
    def __complex_insert( query, parameters ):
        connection = Archive.__connect()
        Archive.__query( connection, query, parameters )
        connection.commit()
        Archive.__disconnect( connection )

    @staticmethod
    def __simple_select( table, fields, where="1=1" ):
        connection = Archive.__connect()
        results = Archive.__query( connection,
                                   """
                                       SELECT {fields} FROM {table} WHERE {where}
                                   """.format(
                                       table=table,
                                       fields=",".join( fields ), # TODO: change to tupples see. Tuples adaptation at http://initd.org/psycopg/docs/usage.html#adapt-date
                                       where=where
                                   ) )

        if results.rowcount > 0:

            for result in Archive.__results( results ):
                yield result

        Archive.__disconnect( connection )

    @staticmethod
    def __is_symbol_registered( symbol ):
        results = Archive.__simple_select( "symbols",
                                           [ "id" ],
                                           where="name='{symbol}'".format( symbol=symbol ) )

        if len( list( results ) ) < 1:
            return False

        return True

    @staticmethod
    def __add_symbol_if_not_registered( symbol ):
        if not Archive.__is_symbol_registered( symbol ):
            Archive.__simple_insert( "symbols", [ "name" ], [ symbol ] )
            return True
        return False

    @staticmethod
    def add_symbol_snapshot( exchange, symbol, timestamp, data ):
        def dumps( obj ): return json.dumps( obj, allow_nan=False )

        if Archive.__add_symbol_if_not_registered( symbol ): Logger.debug( "symbol '{symbol}' added".format( symbol=symbol ) )
        Archive.__complex_insert(
            """
                INSERT INTO symbol_snapshots ( "symbol_id", "timestamp", "data" )
                SELECT symbols.id, items.timestamp, items.data
                FROM ( VALUES ( %(symbol)s, %(timestamp)s, %(data)s::jsonb ) ) items ( "name", "timestamp", "data" )
                LEFT JOIN symbols USING ( "name" );
            """,
            { "symbol": symbol, "timestamp": timestamp, "data": psycopg2.extras.Json( data, dumps=dumps ) }
        ) # TODO: change to tupples see. Tuples adaptation at http://initd.org/psycopg/docs/usage.html#adapt-date

        #Archive.__elasticsearch_put( "symbol_snapshots", data )

        if all( key in data for key in [ "Open" ] ):
            Publisher.send_snapshot( exchange,
                                     symbol,
                                     timestamp,
                                     { "open": data[ "Open" ] } )

    @staticmethod
    def add_symbol_historical( exchange, symbol, timestamp, data ): # TODO: is this really required? bw considerations??

        historical = []

        for item in data:
            list_dict = {}
            for key, value in item.items():
                if key in [ "Volume", "Open" ]: list_dict[ key ] = value
            historical.append( list_dict )

        Publisher.send_historical( exchange, symbol, timestamp, historical )

    @staticmethod
    def add_symbol_tick( exchange, symbol, timestamp, data ):
        if Archive.__add_symbol_if_not_registered( symbol ): Logger.debug( "symbol '{symbol}' added".format( symbol=symbol ) )
        Archive.__complex_insert(
            """
                INSERT INTO symbol_ticks ( "symbol_id", "timestamp", "data" )
                SELECT symbols.id, items.timestamp, items.data
                FROM ( VALUES ( %(symbol)s, %(timestamp)s, %(data)s::jsonb ) ) items ( "name", "timestamp", "data" )
                LEFT JOIN symbols USING ( "name" );
            """,
            { "symbol": symbol, "timestamp": timestamp, "data": psycopg2.extras.Json( data ) }
        ) # TODO: change to tuples see. Tuples adaptation at http://initd.org/psycopg/docs/usage.html#adapt-date

        #Archive.__elasticsearch_put( "symbol_ticks", Utils.dict_combine( data, { "symbol": symbol } ) )

        if all( key in data for key in [ "a00", "b00", "l10", "v00" ] ):
            Publisher.send_tick( exchange,
                                 symbol,
                                 timestamp,
                                 { "ask": data[ "a00" ],
                                   "bid": data[ "b00" ],
                                   "price": data[ "l10" ],
                                   "volume": data[ "v00" ] } )


class Publisher():

    @staticmethod
    def __post( channel, data ):
        data_as_json = json.dumps( data )
        Logger.debug( "received data with '{data}' passing as '{json}'".format( data=data, json=data_as_json ) )
        try:
            Sender.blocking_post( "http://169.254.254.5/publish?id={channel}".format( channel=channel ),
                                  data=base64.b64encode( data_as_json.encode( "ascii" ) ).decode() )
        except Exception as exception: raise RuntimeError( exception )

    @staticmethod
    def send_tick( exchange, symbol, timestamp, data ):
        #TODO: Logger.debug here
        Publisher.__post( "trader",
                          { "type": "tick",
                            "exchange": exchange.name,
                            "symbol": symbol.split( "." )[ 0 ],
                            "timestamp": str( timestamp ),
                            "data": data } )

    @staticmethod
    def send_snapshot( exchange, symbol, timestamp, data ):
        #TODO: Logger.debug here
        Publisher.__post( "trader",
                          { "type": "snapshot",
                            "exchange": exchange.name,
                            "symbol": symbol.split( "." )[ 0 ],
                            "timestamp": str( timestamp ),
                            "data": data } )

    @staticmethod
    def send_historical( exchange, symbol, timestamp, data ):
        #TODO: Logger.debug here
        Publisher.__post( "trader",
                          { "type": "historical",
                            "exchange": exchange.name,
                            "symbol": symbol.split( "." )[ 0 ],
                            "timestamp": str( timestamp ),
                            "data": data } )

    @staticmethod
    def send_annotation( symbol, timestamp, message ):
        # TODO: Logger.debug here
        Publisher.__post( "trader",
                          { "type": "annotation",
                            "symbol": symbol.split( "." )[ 0 ],
                            "timestamp": str( timestamp ),
                            "message": message } )

    @staticmethod
    def send_balance( balance ):
        Publisher.__post( "trader",
                          { "type": "balance",
                            "timestamp": str( datetime.datetime.utcnow() ),
                            "balance": str( balance ) } )


class Interface():
    __socket = None
    __mappings = None

    class Queries():
        @staticmethod
        def help(): # private member access madness
            return "\n".join( sorted(
                [ "{key} {description}".format( key=key.ljust( 25, " " ),
                                                description=value[ "description" ] ) for key, value in Interface._get_mappings().items() ] ) )

        @staticmethod
        def dump_threads(): return "\n\n".join( [ str( thread ) + "\n" + str( traceback.format_stack( sys._current_frames()[ thread.ident ] ) ) for thread in threading.enumerate() ] )

        @staticmethod
        def graceful_shutdown(): return "not implemented"

        @staticmethod
        def forced_shutdown(): return "not implemented"

        @staticmethod
        def ping(): return "PONG"

        @staticmethod
        def dump_config():
            return "\n".join( sorted ( [
                "{name}: {type} '{value}'".format( name=name,
                                                   type=type( getattr( Config, name ) ),
                                                   value=str( getattr( Config, name ) ) )
                for name in Config if not name.startswith( "__" ) ] ) )

        @staticmethod
        def get_config( name ):
            if hasattr( Config, name ):
                return "'{value}' of '{type}'".format( type=type( getattr( Config, name ) ), value=str( getattr( Config, name ) ) )
            else: return "'{name}' not found".format( name=name )

        @staticmethod
        def set_config( name, *args ):
            value = " ".join( args )
            try:
                # TODO: think of a better way to cast than eval, consider logging.debug
                casted_value = eval( "{value}".format( value=value.strip() ), None, None )
            except Exception as exception:
                return "ERROR: could not cast '{value}' with error '{error}'".format( value=value, error=exception )

            if type( casted_value ) is type( getattr( Config, name ) ):
                setattr( Config, name, casted_value )
                return "'{name}' updated to '{value}'".format( name=name, value=getattr( Config, name ) )
            else:
                return "source {source} not the same type as destination {destination}".format(
                    source=type( casted_value ), destination=type( getattr( Config, name ) ) )

        @staticmethod
        def list_scheduler_jobs(): return "\n".join( [ str( item ) for item in Scheduler.list_active_jobs() ] )

        @staticmethod
        def list_symbol_following(): return "\n".join( Intelligence.MarketRisers.list_following() )

        @staticmethod
        def list_symbol_followed():
            return "\n".join( [ "'{name}': '{value}'".format(
                name=key, value=value ) for key, value in Intelligence.MarketRisers.list_followed().items() ] )

        @staticmethod
        def get_orderbook_balance(): return str( OrderBook.get_balance() )

        @staticmethod
        def list_orderbook_active(): return "\n".join( [ str( item ) for item in OrderBook.list_active() ] )

        @staticmethod
        def list_orderbook_history(): return "\n".join( [ str( item ) for item in OrderBook.list_history() ] )

        @staticmethod
        def reset_balance():
            OrderBook.reset_balance()
            return "balance is now '{balance}'".format( balance=OrderBook.get_balance() )

    @staticmethod
    def __process_line( line ):
        if " " in line:
            command, arguments = line.split( " ", 1 )
            arguments = arguments.split( " " )
        else:
            command = line.rstrip()
            arguments = list()

        command = command.upper() # make life a little easier

        if command in Interface.__mappings.keys():
            Logger.debug( "running mapping for '{command}' with arguments '{args}'".format( command=command, args=arguments ) )
            return "COMMAND: '{command}'\nARGUMENTS: '{arguments}'\n\n{results}".format(
                command=command, arguments=arguments, results=Interface.__mappings[ command.upper() ][ "function" ]( *arguments ) )

        Logger.debug( "no mapping found for '{data}'".format( data=line ) )
        return "ERROR: command not found"

    @staticmethod
    def __prompt(): return Config.INTERFACE_PROMPT

    @staticmethod
    def __message( message ): return "{message}\n\n".format( message=message )

    @staticmethod
    def __message_and_prompt( message ):
        return "{message}{prompt}".format( message=Interface.__message( message ), prompt=Interface.__prompt() )

    @staticmethod
    def _get_mappings(): return Interface.__mappings

    @staticmethod
    def setup_mappings():
        Interface.__mappings = {
            "RESET_BALANCE":  {
                "function": Interface.Queries.reset_balance(),
                "description": "reset balance to default from config" },
            "GET_ORDERBOOK_BALANCE": {
                "function": Interface.Queries.get_orderbook_balance,
                "description": "return current balance from orderbook" },
            "LIST_ORDERBOOK_ACTIVE": {
                "function": Interface.Queries.list_orderbook_active,
                "description": "get active symbols in orderbook" },
            "LIST_ORDERBOOK_HISTORY": {
                "function": Interface.Queries.list_orderbook_history,
                "description": "get orderbook history" },
            "LIST_SCHEDULER_JOBS": {
                "function": Interface.Queries.list_scheduler_jobs,
                "description": "list active jobs in the scheduler" },
            "LIST_SYMBOLS_FOLLOWING": {
                "function": Interface.Queries.list_symbol_following,
                "description": "list symbols being followed in market risers" },
            "LIST_SYMBOLS_FOLLOWED": {
                "function": Interface.Queries.list_symbol_followed,
                "description": "list symbols previously followed" },
            "DUMP_CONFIG": {
                "function": Interface.Queries.dump_config,
                "description": "dump current config" },
            "GET_CONFIG": {
                "function": Interface.Queries.get_config,
                "description": "[name] get current setting for config variable" },
            "SET_CONFIG": {
                "function": Interface.Queries.set_config,
                "description": "[name] [value] override defaults for config variable with autocasting" },
            "GRACEFUL_SHUTDOWN": {
                "function": Interface.Queries.graceful_shutdown,
                "description": "shutdown process gracefully" },
            "FORCED_SHUTDOWN": {
                "function": Interface.Queries.forced_shutdown,
                "description": "shutdown process forcefully" },
            "LIST_THREADS": {
                "function": Interface.Queries.dump_threads,
                "description": "dump stack traces of all running threads" },
            "PING": {
                "function": Interface.Queries.ping,
                "description": "pong" },
            "HELP": {
                "function": Interface.Queries.help,
                "description": "shows available functions with descriptions" } }

    @staticmethod
    def start():
        Interface.setup_mappings()

        if os.path.exists( Config.INTERFACE_SOCKET_PATH ):
            os.remove( Config.INTERFACE_SOCKET_PATH )
            Logger.debug( "socket from previous execution cleaned" )

        # TODO: move this back to asyncio with start_unix_server
        Interface.__socket = socket.socket( family=socket.AF_UNIX, type=socket.SOCK_STREAM )
        Interface.__socket.bind( Config.INTERFACE_SOCKET_PATH )
        Interface.__socket.listen( 5 )
        Logger.debug( "socket bound" )

    @staticmethod
    def event_loop():
        while True:
            connection, address = Interface.__socket.accept()
            Logger.debug( "connection accepted" )

            connection.send( Interface.__prompt().encode() )

            break_outer = False

            while not break_outer:
                data = connection.recv( 1024 )

                if not data:
                    Logger.debug( "received no data on stream, assuming EOF" )
                    break

                decoded_data = data.decode()

                if not decoded_data: continue
                else:
                    for line in decoded_data.splitlines():
                        Logger.debug( "processed line is '{line}'".format( line=line ) )

                        if line.upper() == "QUIT":
                            break_outer = True
                            break
                        elif line == "":
                            results = Interface.__message_and_prompt( "ERROR: no command supplied, try 'HELP' if unsure" )
                        else:
                            try:
                                results = Interface.__message_and_prompt( Interface.__process_line( line ) )
                            except TypeError as exception:
                                Logger.warn( "bad interface request with typerror '{error}'".format( error=exception ) )
                                results = Interface.__message_and_prompt( "ERROR: incorrect arguments supplied" )
                            except Exception as exception:
                                Logger.warn( "bad interface request with exception '{error}'".format( error=exception ) )
                                results = Interface.__message_and_prompt( "ERROR: unspecified error" )

                        connection.send( results.encode() )
                        Logger.debug( "'{results}' sent".format( results=results ) )

            connection.close()
            Logger.debug( "connection closed" )

    @staticmethod
    def stop():
        Interface.__socket.close()
        Logger.debug( "event loop closed" )

        os.remove( Config.INTERFACE_SOCKET_PATH )
        Logger.debug( "socket file removed" )


class Manager():
    @staticmethod
    def start():
        Logger.start()
        Logger.info( "logger started" )

        Interface.start()
        Logger.debug( "interface started" )

        Scheduler.start()
        Logger.debug( "scheduler started" )

        Currency.start()
        Logger.debug( "scheduled periodic currency update" )

        OrderBook.start()
        Publisher.send_balance( OrderBook.get_balance() ) # TODO: this does'nt feel right here, needs moving
        Logger.debug( "orderbook started and initial balance published" )

        Intelligence.start()
        Logger.debug( "intelligence started" )

    @staticmethod
    def stop():
        Interface.stop()
        Logger.debug( "interface stopped" )

        Scheduler.stop( forced=True )
        Logger.debug( "scheduler stopped" )

        Intelligence.stop()
        Logger.debug( "intelligence stopped" )

        OrderBook.stop()
        Logger.debug( "orderbook stopped" )


# start of global variables
# *** USE SPARINGLY ***
# *** NO, SERIOUSLY ***
# *** THEY'RE SCARY ***
time_to_leave = False
# end of global variables

def shutdown(): # this was broken by the interface event loop
    Logger.debug( "main shutdown called" )
    time_to_leave = True
    return

if __name__ == '__main__':
    # TODO: abuse python's anonymous functions
    def interrupt_handler( signal, frame ): shutdown()
    signal.signal( signal.SIGINT, interrupt_handler )

    Logger.debug( "starting manager" )
    Manager.start()

    Logger.debug( "entering interface loop" )
    Interface.event_loop() # put this in a thread as it breaks shutdown() - needs testing

    Logger.debug( "shutting down manager" )
    Manager.stop()

    Logger.debug( "daisy, daisy, give me your answer do..." )
else:
    print( "this is *NOT* intended to be imported" )
